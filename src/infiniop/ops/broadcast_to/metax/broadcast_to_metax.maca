#include "broadcast_to_metax.h"
#include "../../../devices/metax/metax_common.h"
#include "../../../devices/metax/metax_handle.h"

#include <mcr/mc_runtime.h>
#include <cstdint>
#include <algorithm>
#include <vector>
#include <cmath>
#include <cstdio>

#include <maca_fp16.h>
#include <maca_bfloat16.h>
using nv_bfloat16  = __maca_bfloat16;
using nv_bfloat162 = __maca_bfloat162;

namespace op::broadcast_to::metax {

// ==================================================================
// 1. Kernel 定义
// ==================================================================

// 最大维度需与 BroadcastToInfo::MAX_DIM 保持一致
static constexpr int MAX_DIM = 8;

struct BroadcastStrides {
    int64_t out_strides[MAX_DIM];
    int64_t in_strides[MAX_DIM];
};

template <typename T>
__global__ void broadcast_kernel(
    T * __restrict__ output,        // Output data pointer
    const T * __restrict__ input,   // Input data pointer
    int ndim,
    size_t count,                   // Total elements in output
    BroadcastStrides strides) {     // Strides passed by value

    size_t idx = blockIdx.x * blockDim.x + threadIdx.x;

    if (idx < count) {
        size_t temp_idx     = idx;
        size_t input_offset = 0;
#pragma unroll
        for (int i = 0; i < MAX_DIM; ++i) {
            if (i >= ndim) break;

            int64_t out_s = strides.out_strides[i];
            int64_t in_s  = strides.in_strides[i];
            size_t coord  = temp_idx / out_s;
            temp_idx     %= out_s;
            input_offset += coord * in_s;
        }

        output[idx] = input[input_offset];
    }
}

// ==================================================================
// 2. Kernel Launch Logic
// ==================================================================
template <typename T>
void launch_kernel(
    void *output, 
    const void *input, 
    const BroadcastToInfo& info,
    void *stream) {

    auto in_ptr  = reinterpret_cast<const T *>(input);
    auto out_ptr = reinterpret_cast<T *>(output);
    
    auto mc_stream = reinterpret_cast<mcStream_t>(stream);

    BroadcastStrides strides;
    for (int i = 0; i < BroadcastToInfo::MAX_DIM; ++i) {
        strides.out_strides[i] = info._out_strides[i];
        strides.in_strides[i]  = info._in_strides[i];
    }

    size_t count      = info.count();
    size_t block_size = 256;
    size_t grid_size  = (count + block_size - 1) / block_size;
    if (grid_size == 0) grid_size = 1;

    broadcast_kernel<T>
        <<<grid_size, block_size, 0, mc_stream>>>(
            out_ptr,
            in_ptr,
            info.ndim(),
            count,
            strides
        );
}

// ==================================================================
// 3. Descriptor 实现
// ==================================================================
struct Descriptor::Opaque {};

Descriptor::~Descriptor() { 
    if (_opaque) {
        delete _opaque;
    }
}

infiniStatus_t Descriptor::create(
    infiniopHandle_t handle_,
    Descriptor **desc_ptr,
    infiniopTensorDescriptor_t out_desc, 
    const std::vector<infiniopTensorDescriptor_t> &input_descs) {

    auto handle = reinterpret_cast<device::metax::Handle *>(handle_);

    auto info_result = BroadcastToInfo::create(out_desc, input_descs);
    if (!info_result) {
        return info_result.status();
    }

    size_t workspace_size = 0;  // broadcast_to 不需要额外 workspace

    *desc_ptr = new Descriptor(
        new Opaque(),
        info_result.take(),
        workspace_size,
        handle->device,
        handle->device_id
    );
    
    return INFINI_STATUS_SUCCESS;
}

infiniStatus_t Descriptor::calculate(
    void *workspace, 
    size_t workspace_size, 
    void *output,
    const std::vector<const void *> &inputs, 
    void *stream) const {

    if (inputs.size() != 1) {
        return INFINI_STATUS_BAD_PARAM;
    }
    const void *input = inputs[0];

    auto dtype = _info.dtype();
    switch (dtype) {
    case INFINI_DTYPE_F16:
        launch_kernel<__half>(output, input, _info, stream);
        break;
    case INFINI_DTYPE_BF16:
        launch_kernel<nv_bfloat16>(output, input, _info, stream);
        break;
    case INFINI_DTYPE_F32:
        launch_kernel<float>(output, input, _info, stream);
        break;
    case INFINI_DTYPE_F64:
        launch_kernel<double>(output, input, _info, stream);
        break;
    case INFINI_DTYPE_I64:
        launch_kernel<int64_t>(output, input, _info, stream);
        break;
    case INFINI_DTYPE_I32:
        launch_kernel<int32_t>(output, input, _info, stream);
        break;
    case INFINI_DTYPE_U8:
        launch_kernel<uint8_t>(output, input, _info, stream);
        break;
    case INFINI_DTYPE_I8:
        launch_kernel<int8_t>(output, input, _info, stream);
        break;
    default:
        return INFINI_STATUS_BAD_TENSOR_DTYPE;
    }

    return INFINI_STATUS_SUCCESS;
}

} // namespace op::broadcast_to::metax
