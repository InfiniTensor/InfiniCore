#include "kron_metax.h"
#include "../cuda/kernel.cuh"
#include "../../../utils.h"
#include <cuda_bf16.h>
#include <cuda_fp16.h>

namespace op::kron::metax {

Descriptor::~Descriptor() = default;

infiniStatus_t Descriptor::create(
    infiniopHandle_t handle,
    Descriptor **desc_ptr,
    infiniopTensorDescriptor_t y_desc,
    infiniopTensorDescriptor_t a_desc,
    infiniopTensorDescriptor_t b_desc) {

    auto dtype = a_desc->dtype();
    CHECK_DTYPE(dtype, INFINI_DTYPE_F16, INFINI_DTYPE_F32, INFINI_DTYPE_F64, INFINI_DTYPE_BF16);

    auto a_shape = a_desc->shape();
    auto b_shape = b_desc->shape();
    auto y_shape = y_desc->shape();

    if (a_shape.size() != b_shape.size()) {
        return INFINI_STATUS_BAD_TENSOR_SHAPE;
    }

    size_t ndim = a_shape.size();
    std::vector<size_t> expected_y_shape(ndim);
    for (size_t i = 0; i < ndim; ++i) {
        expected_y_shape[i] = a_shape[i] * b_shape[i];
    }

    if (y_shape != expected_y_shape) {
        return INFINI_STATUS_BAD_TENSOR_SHAPE;
    }

    *desc_ptr = new Descriptor(dtype, ndim, a_shape, b_shape, y_shape,
                               a_desc->numel(), b_desc->numel(), y_desc->numel(),
                               handle->device, handle->device_id);
    return INFINI_STATUS_SUCCESS;
}

infiniStatus_t Descriptor::calculate(
    void *workspace,
    size_t workspace_size,
    void *y,
    const void *a,
    const void *b,
    void *stream) const {

    if (workspace_size < this->workspaceSize()) {
        return INFINI_STATUS_INSUFFICIENT_WORKSPACE;
    }

    auto hc_stream = reinterpret_cast<hcStream_t>(stream);
    size_t *shape_data = reinterpret_cast<size_t *>(workspace);
    std::memcpy(shape_data, a_shape.data(), ndim * sizeof(size_t));
    std::memcpy(shape_data + ndim, b_shape.data(), ndim * sizeof(size_t));
    std::memcpy(shape_data + 2 * ndim, y_shape.data(), ndim * sizeof(size_t));

    constexpr int BLOCK_SIZE = 256;
    int num_blocks = (y_size + BLOCK_SIZE - 1) / BLOCK_SIZE;

    switch (_dtype) {
    case INFINI_DTYPE_F16:
        cuda::kron_kernel<half><<<num_blocks, BLOCK_SIZE, 0, hc_stream>>>(
            reinterpret_cast<half *>(y),
            reinterpret_cast<const half *>(a),
            reinterpret_cast<const half *>(b),
            y_size, ndim, shape_data, shape_data + ndim, shape_data + 2 * ndim);
        break;
    case INFINI_DTYPE_BF16:
        cuda::kron_kernel<cuda_bfloat16><<<num_blocks, BLOCK_SIZE, 0, hc_stream>>>(
            reinterpret_cast<cuda_bfloat16 *>(y),
            reinterpret_cast<const cuda_bfloat16 *>(a),
            reinterpret_cast<const cuda_bfloat16 *>(b),
            y_size, ndim, shape_data, shape_data + ndim, shape_data + 2 * ndim);
        break;
    case INFINI_DTYPE_F32:
        cuda::kron_kernel<float><<<num_blocks, BLOCK_SIZE, 0, hc_stream>>>(
            reinterpret_cast<float *>(y),
            reinterpret_cast<const float *>(a),
            reinterpret_cast<const float *>(b),
            y_size, ndim, shape_data, shape_data + ndim, shape_data + 2 * ndim);
        break;
    case INFINI_DTYPE_F64:
        cuda::kron_kernel<double><<<num_blocks, BLOCK_SIZE, 0, hc_stream>>>(
            reinterpret_cast<double *>(y),
            reinterpret_cast<const double *>(a),
            reinterpret_cast<const double *>(b),
            y_size, ndim, shape_data, shape_data + ndim, shape_data + 2 * ndim);
        break;
    default:
        return INFINI_STATUS_BAD_TENSOR_DTYPE;
    }

    return INFINI_STATUS_SUCCESS;
}

} // namespace op::kron::metax
