#include "batch_norm_backward_metax.h"
#include "../../../devices/metax/metax_common.h"
#include "../../../devices/metax/metax_kernel_common.h"
#include "../../../../utils.h"
#include "batch_norm_backward_kernel.cuh"

namespace op::batch_norm_backward::metax {

/**
 * @brief Launch BatchNorm backward kernel for MetaX devices
 * 
 * @tparam T Data type for input/output tensors
 */
template <typename T>
infiniStatus_t launchBatchNormBackwardKernel(
    T *grad_input,
    T *grad_weight,
    T *grad_bias,
    const T *grad_output,
    const T *input,
    const T *weight,
    const T *running_mean,
    const T *running_var,
    const BatchNormBackwardInfo& info,
    hcStream_t stream
) {
    constexpr unsigned int BLOCK_SIZE = 256;
    
    size_t batch_size = info._batch_size;
    size_t channels = info._channels;
    size_t spatial_size = info._spatial_size;
    float momentum = info.momentum;
    float eps = info.eps;
    
    // 每个channel使用一个block
    dim3 grid(channels);
    dim3 block(BLOCK_SIZE);
    
    batchNormBackwardKernel<BLOCK_SIZE, T><<<grid, block, 0, stream>>>(
        grad_input, grad_weight, grad_bias,
        grad_output, input, weight,
        running_mean, running_var,
        batch_size, channels, spatial_size,
        momentum, eps);
    
    // Check kernel launch error
    hcError_t err = hcGetLastError();
    if (err != hcSuccess) {
        return INFINI_STATUS_INTERNAL_ERROR;
    }
    
    // Wait for kernel completion
    err = hcStreamSynchronize(stream);
    if (err != hcSuccess) {
        return INFINI_STATUS_INTERNAL_ERROR;
    }
    
    return INFINI_STATUS_SUCCESS;
}

Descriptor::~Descriptor() = default;

infiniStatus_t Descriptor::create(
    infiniopHandle_t handle_,
    Descriptor **desc_ptr,
    infiniopTensorDescriptor_t grad_input_desc,
    infiniopTensorDescriptor_t grad_weight_desc,
    infiniopTensorDescriptor_t grad_bias_desc,
    infiniopTensorDescriptor_t grad_output_desc,
    infiniopTensorDescriptor_t input_desc,
    infiniopTensorDescriptor_t weight_desc,
    infiniopTensorDescriptor_t running_mean_desc,
    infiniopTensorDescriptor_t running_var_desc,
    float momentum,
    float eps
) {
    // 验证输入参数
    if (!handle_ || !desc_ptr || !grad_input_desc || !grad_weight_desc || 
        !grad_bias_desc || !grad_output_desc || !input_desc || !weight_desc ||
        !running_mean_desc || !running_var_desc) {
        return INFINI_STATUS_BAD_PARAM;
    }
    
    if (momentum < 0.0f || momentum > 1.0f || eps <= 0.0f) {
        return INFINI_STATUS_BAD_PARAM;
    }
    
    auto handle = static_cast<device::metax::Handle *>(handle_);
    auto dtype = input_desc->dtype();
    
    // 检查数据类型支持
    if (dtype != INFINI_DTYPE_F16 && dtype != INFINI_DTYPE_F32 && dtype != INFINI_DTYPE_BF16) {
        return INFINI_STATUS_BAD_TENSOR_DTYPE;
    }
    
    // 检查数据类型一致性
    if (input_desc->dtype() != grad_input_desc->dtype() ||
        input_desc->dtype() != grad_output_desc->dtype() ||
        input_desc->dtype() != weight_desc->dtype() ||
        input_desc->dtype() != grad_weight_desc->dtype() ||
        input_desc->dtype() != grad_bias_desc->dtype() ||
        input_desc->dtype() != running_mean_desc->dtype() ||
        input_desc->dtype() != running_var_desc->dtype()) {
        return INFINI_STATUS_BAD_PARAM;
    }
    
    // 检查形状兼容性
    if (input_desc->ndim() < 2) {
        return INFINI_STATUS_BAD_PARAM;
    }
    
    // 输入和梯度输出形状应该相同
    if (input_desc->ndim() != grad_output_desc->ndim() ||
        input_desc->ndim() != grad_input_desc->ndim()) {
        return INFINI_STATUS_BAD_PARAM;
    }
    
    for (size_t i = 0; i < input_desc->ndim(); ++i) {
        if (input_desc->dim(i) != grad_output_desc->dim(i) ||
            input_desc->dim(i) != grad_input_desc->dim(i)) {
            return INFINI_STATUS_BAD_PARAM;
        }
    }
    
    // weight, bias, running_mean, running_var 应该是1D张量，长度为channels
    size_t channels = input_desc->dim(1);
    if (weight_desc->ndim() != 1 || weight_desc->dim(0) != channels ||
        grad_weight_desc->ndim() != 1 || grad_weight_desc->dim(0) != channels ||
        grad_bias_desc->ndim() != 1 || grad_bias_desc->dim(0) != channels ||
        running_mean_desc->ndim() != 1 || running_mean_desc->dim(0) != channels ||
        running_var_desc->ndim() != 1 || running_var_desc->dim(0) != channels) {
        return INFINI_STATUS_BAD_PARAM;
    }
    
    // 创建BatchNormBackwardInfo
    auto result = BatchNormBackwardInfo::create(
        grad_input_desc, grad_weight_desc, grad_bias_desc,
        grad_output_desc, input_desc, weight_desc,
        running_mean_desc, running_var_desc, momentum, eps);
    if (!result) {
        return result.status();
    }
    auto info = result.take();
    
    // MetaX实现不需要额外的workspace
    size_t workspace_size = 0;
    
    *desc_ptr = new Descriptor(info, workspace_size, handle->device, handle->device_id);
    
    return INFINI_STATUS_SUCCESS;
}

infiniStatus_t Descriptor::calculate(
    void *workspace,
    size_t workspace_size,
    void *grad_input,
    void *grad_weight,
    void *grad_bias,
    const void *grad_output,
    const void *input,
    const void *weight,
    const void *running_mean,
    const void *running_var,
    void *stream
) const {
    if (!grad_input || !grad_weight || !grad_bias || !grad_output || 
        !input || !weight || !running_mean || !running_var) {
        return INFINI_STATUS_BAD_PARAM;
    }
    
    hcStream_t hc_stream = static_cast<hcStream_t>(stream);
    
    // 根据数据类型分发
    switch (_info.dtype) {
        case INFINI_DTYPE_F32:
            return calculate_batch_norm_backward<float>(
                workspace, grad_input, grad_weight, grad_bias,
                grad_output, input, weight, running_mean, running_var,
                _info, stream
            );
        case INFINI_DTYPE_F16:
            return calculate_batch_norm_backward<__half>(
                workspace, grad_input, grad_weight, grad_bias,
                grad_output, input, weight, running_mean, running_var,
                _info, stream
            );
        case INFINI_DTYPE_BF16:
            return calculate_batch_norm_backward<__hpcc_bfloat16>(
                workspace, grad_input, grad_weight, grad_bias,
                grad_output, input, weight, running_mean, running_var,
                _info, stream
            );
        default:
            return INFINI_STATUS_BAD_TENSOR_DTYPE;
    }
}

template <typename T>
infiniStatus_t Descriptor::calculate_batch_norm_backward(
    void *workspace,
    void *grad_input_data,
    void *grad_weight_data,
    void *grad_bias_data,
    const void *grad_output_data,
    const void *input_data,
    const void *weight_data,
    const void *running_mean_data,
    const void *running_var_data,
    const BatchNormBackwardInfo &info,
    void *stream) const {
    
    auto grad_input = static_cast<T*>(grad_input_data);
    auto grad_weight = static_cast<T*>(grad_weight_data);
    auto grad_bias = static_cast<T*>(grad_bias_data);
    auto grad_output = static_cast<const T*>(grad_output_data);
    auto input = static_cast<const T*>(input_data);
    auto weight = static_cast<const T*>(weight_data);
    auto running_mean = static_cast<const T*>(running_mean_data);
    auto running_var = static_cast<const T*>(running_var_data);
    auto hc_stream = static_cast<hcStream_t>(stream);
    
    // Launch BatchNorm backward kernel
    infiniStatus_t status = launchBatchNormBackwardKernel<T>(
        grad_input, grad_weight, grad_bias,
        grad_output, input, weight,
        running_mean, running_var,
        info, hc_stream
    );
    if (status != INFINI_STATUS_SUCCESS) {
        return status;
    }
    
    return INFINI_STATUS_SUCCESS;
}

// 显式实例化模板
template infiniStatus_t Descriptor::calculate_batch_norm_backward<float>(
    void *, void *, void *, void *, const void *, const void *, const void *,
    const void *, const void *, const BatchNormBackwardInfo &, void *) const;

template infiniStatus_t Descriptor::calculate_batch_norm_backward<__half>(
    void *, void *, void *, void *, const void *, const void *, const void *,
    const void *, const void *, const BatchNormBackwardInfo &, void *) const;

template infiniStatus_t Descriptor::calculate_batch_norm_backward<__hpcc_bfloat16>(
    void *, void *, void *, void *, const void *, const void *, const void *,
    const void *, const void *, const BatchNormBackwardInfo &, void *) const;

} // namespace op::batch_norm_backward::metax